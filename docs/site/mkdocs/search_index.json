{
    "docs": [
        {
            "location": "/", 
            "text": "DiffBase.jl Documentation\n\n\n#\n\n\nDiffBase.GradientResult\n \n \nMethod\n.\n\n\nGradientResult(x::AbstractArray)\n\n\n\n\nConstruct a \nDiffResult\n that can be used for gradient calculations where \nx\n is the input to the target function.\n\n\nNote that \nGradientResult\n allocates its own storage; \nx\n is only used for type and shape information. If you want to allocate storage yourself, use the \nDiffResult\n constructor instead.\n\n\nsource\n\n\n#\n\n\nDiffBase.HessianResult\n \n \nMethod\n.\n\n\nHessianResult(x::AbstractArray)\n\n\n\n\nConstruct a \nDiffResult\n that can be used for Hessian calculations where \nx\n is the input to the target function.\n\n\nNote that \nHessianResult\n allocates its own storage; \nx\n is only used for type and shape information. If you want to allocate storage yourself, use the \nDiffResult\n constructor instead.\n\n\nsource\n\n\n#\n\n\nDiffBase.JacobianResult\n \n \nMethod\n.\n\n\nJacobianResult(y::AbstractArray, x::AbstractArray)\n\n\n\n\nConstruct a \nDiffResult\n that can be used for Jacobian calculations where \nx\n is the input to the target function, and \ny\n is the output (e.g. when taking the Jacobian of \nf!(y, x)\n).\n\n\nLike the single argument version, \ny\n and \nx\n are only used for type and shape information and are not stored in the returned \nDiffResult\n.\n\n\nsource\n\n\n#\n\n\nDiffBase.JacobianResult\n \n \nMethod\n.\n\n\nJacobianResult(x::AbstractArray)\n\n\n\n\nConstruct a \nDiffResult\n that can be used for Jacobian calculations where \nx\n is the input to the target function. This method assumes that the target function's output dimension equals its input dimension.\n\n\nNote that \nJacobianResult\n allocates its own storage; \nx\n is only used for type and shape information. If you want to allocate storage yourself, use the \nDiffResult\n constructor instead.\n\n\nsource\n\n\n#\n\n\nDiffBase.DiffResult\n \n \nMethod\n.\n\n\nDiffResult(value, derivs...)\n\n\n\n\nEquivalent to \nDiffResult(value, derivs::Tuple)\n, where \nderivs...\n is the splatted form of \nderivs::Tuple\n.\n\n\nsource\n\n\n#\n\n\nDiffBase.DiffResult\n \n \nMethod\n.\n\n\nDiffResult(value, derivs::Tuple)\n\n\n\n\nReturn a \nDiffResult\n instance where values will be stored in the provided \nvalue\n storage and derivatives will be stored in the provided \nderivs\n storage.\n\n\nNote that the arguments can be \nNumber\ns or \nAbstractArray\ns, depending on the dimensionality of your target function.\n\n\nsource\n\n\n#\n\n\nDiffBase.derivative\n \n \nFunction\n.\n\n\nderivative(r::DiffResult, ::Type{Val{i}} = Val{1})\n\n\n\n\nReturn the \nith\n derivative stored in \nr\n, defaulting to the first derivative.\n\n\nNote that this method returns a reference, not a copy. Thus, if \nderivative(r)\n is mutable, mutating \nderivative(r)\n will mutate \nr\n.\n\n\nsource\n\n\n#\n\n\nDiffBase.derivative!\n \n \nFunction\n.\n\n\nderivative!(f, r::DiffResult, x, ::Type{Val{i}} = Val{1})\n\n\n\n\nLike \nderivative!(r::DiffResult, x, Val{i})\n, but with \nf\n applied to each element, such that \nderivative(r, Val{i}) == map(f, x)\n.\n\n\nsource\n\n\n#\n\n\nDiffBase.derivative!\n \n \nFunction\n.\n\n\nderivative!(r::DiffResult, x, ::Type{Val{i}} = Val{1})\n\n\n\n\nCopy \nx\n into \nr\n's \nith\n derivative storage, such that \nderivative(r, Val{i}) == x\n.\n\n\nsource\n\n\n#\n\n\nDiffBase.gradient\n \n \nMethod\n.\n\n\ngradient(r::DiffResult)\n\n\n\n\nReturn the gradient stored in \nr\n (equivalent to \nderivative(r)\n).\n\n\nNote that this method returns a reference, not a copy. Thus, if \ngradient(r)\n is mutable, mutating \ngradient(r)\n will mutate \nr\n.\n\n\nsource\n\n\n#\n\n\nDiffBase.hessian\n \n \nMethod\n.\n\n\nhessian(r::DiffResult)\n\n\n\n\nReturn the Hessian stored in \nr\n (equivalent to \nderivative(r, Val{2})\n).\n\n\nNote that this method returns a reference, not a copy. Thus, if \nhessian(r)\n is mutable, mutating \nhessian(r)\n will mutate \nr\n.\n\n\nsource\n\n\n#\n\n\nDiffBase.jacobian\n \n \nMethod\n.\n\n\njacobian(r::DiffResult)\n\n\n\n\nReturn the Jacobian stored in \nr\n (equivalent to \nderivative(r)\n).\n\n\nNote that this method returns a reference, not a copy. Thus, if \njacobian(r)\n is mutable, mutating \njacobian(r)\n will mutate \nr\n.\n\n\nsource\n\n\n#\n\n\nDiffBase.value!\n \n \nMethod\n.\n\n\nvalue!(f, r::DiffResult, x)\n\n\n\n\nLike \nvalue!(r::DiffResult, x)\n, but with \nf\n applied to each element, such that \nvalue(r) == map(f, x)\n.\n\n\nsource\n\n\n#\n\n\nDiffBase.value!\n \n \nMethod\n.\n\n\nvalue!(r::DiffResult, x)\n\n\n\n\nCopy \nx\n into \nr\n's value storage, such that \nvalue(r) == x\n.\n\n\nsource\n\n\n#\n\n\nDiffBase.value\n \n \nMethod\n.\n\n\nvalue(r::DiffResult)\n\n\n\n\nReturn the primal value stored in \nr\n.\n\n\nNote that this method returns a reference, not a copy. Thus, if \nvalue(r)\n is mutable, mutating \nvalue(r)\n will mutate \nr\n.\n\n\nsource", 
            "title": "Home"
        }, 
        {
            "location": "/#diffbasejl-documentation", 
            "text": "#  DiffBase.GradientResult     Method .  GradientResult(x::AbstractArray)  Construct a  DiffResult  that can be used for gradient calculations where  x  is the input to the target function.  Note that  GradientResult  allocates its own storage;  x  is only used for type and shape information. If you want to allocate storage yourself, use the  DiffResult  constructor instead.  source  #  DiffBase.HessianResult     Method .  HessianResult(x::AbstractArray)  Construct a  DiffResult  that can be used for Hessian calculations where  x  is the input to the target function.  Note that  HessianResult  allocates its own storage;  x  is only used for type and shape information. If you want to allocate storage yourself, use the  DiffResult  constructor instead.  source  #  DiffBase.JacobianResult     Method .  JacobianResult(y::AbstractArray, x::AbstractArray)  Construct a  DiffResult  that can be used for Jacobian calculations where  x  is the input to the target function, and  y  is the output (e.g. when taking the Jacobian of  f!(y, x) ).  Like the single argument version,  y  and  x  are only used for type and shape information and are not stored in the returned  DiffResult .  source  #  DiffBase.JacobianResult     Method .  JacobianResult(x::AbstractArray)  Construct a  DiffResult  that can be used for Jacobian calculations where  x  is the input to the target function. This method assumes that the target function's output dimension equals its input dimension.  Note that  JacobianResult  allocates its own storage;  x  is only used for type and shape information. If you want to allocate storage yourself, use the  DiffResult  constructor instead.  source  #  DiffBase.DiffResult     Method .  DiffResult(value, derivs...)  Equivalent to  DiffResult(value, derivs::Tuple) , where  derivs...  is the splatted form of  derivs::Tuple .  source  #  DiffBase.DiffResult     Method .  DiffResult(value, derivs::Tuple)  Return a  DiffResult  instance where values will be stored in the provided  value  storage and derivatives will be stored in the provided  derivs  storage.  Note that the arguments can be  Number s or  AbstractArray s, depending on the dimensionality of your target function.  source  #  DiffBase.derivative     Function .  derivative(r::DiffResult, ::Type{Val{i}} = Val{1})  Return the  ith  derivative stored in  r , defaulting to the first derivative.  Note that this method returns a reference, not a copy. Thus, if  derivative(r)  is mutable, mutating  derivative(r)  will mutate  r .  source  #  DiffBase.derivative!     Function .  derivative!(f, r::DiffResult, x, ::Type{Val{i}} = Val{1})  Like  derivative!(r::DiffResult, x, Val{i}) , but with  f  applied to each element, such that  derivative(r, Val{i}) == map(f, x) .  source  #  DiffBase.derivative!     Function .  derivative!(r::DiffResult, x, ::Type{Val{i}} = Val{1})  Copy  x  into  r 's  ith  derivative storage, such that  derivative(r, Val{i}) == x .  source  #  DiffBase.gradient     Method .  gradient(r::DiffResult)  Return the gradient stored in  r  (equivalent to  derivative(r) ).  Note that this method returns a reference, not a copy. Thus, if  gradient(r)  is mutable, mutating  gradient(r)  will mutate  r .  source  #  DiffBase.hessian     Method .  hessian(r::DiffResult)  Return the Hessian stored in  r  (equivalent to  derivative(r, Val{2}) ).  Note that this method returns a reference, not a copy. Thus, if  hessian(r)  is mutable, mutating  hessian(r)  will mutate  r .  source  #  DiffBase.jacobian     Method .  jacobian(r::DiffResult)  Return the Jacobian stored in  r  (equivalent to  derivative(r) ).  Note that this method returns a reference, not a copy. Thus, if  jacobian(r)  is mutable, mutating  jacobian(r)  will mutate  r .  source  #  DiffBase.value!     Method .  value!(f, r::DiffResult, x)  Like  value!(r::DiffResult, x) , but with  f  applied to each element, such that  value(r) == map(f, x) .  source  #  DiffBase.value!     Method .  value!(r::DiffResult, x)  Copy  x  into  r 's value storage, such that  value(r) == x .  source  #  DiffBase.value     Method .  value(r::DiffResult)  Return the primal value stored in  r .  Note that this method returns a reference, not a copy. Thus, if  value(r)  is mutable, mutating  value(r)  will mutate  r .  source", 
            "title": "DiffBase.jl Documentation"
        }
    ]
}